{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T22:37:32.749889Z",
     "start_time": "2025-09-20T22:37:32.748087Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Thai Grapheme Classification Algorithm\n",
    "\n",
    "This algorithm classifies Thai graphemes into **three main classes**, with subclasses, plus a special case for **อ**.\n",
    "\n",
    "1. **ฐาน (tan)** - *foundation class*\n",
    "   Consonant letters that act as the **base** for dependent marks (vowels, tone marks, etc.).\n",
    "\n",
    "2. **สระ (sara)** - *vowel class*\n",
    "   Vowel graphemes (both independent and dependent), which attach to a foundation consonant.\n",
    "\n",
    "3. **ยุกต์ (yuk)** - *dependent class*\n",
    "   Tone marks and other diacritics that cannot exist without a foundation consonant.\n",
    "\n",
    "4. **ข้อยกเว้น (kho yok waen)** - *exception class*\n",
    "   The consonant **อ** is treated separately, since it functions both as a **foundation** (carrier consonant) and as part of certain **vowel symbols**.\n",
    "\n"
   ],
   "id": "d244a6a94349f29e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T22:37:32.756532Z",
     "start_time": "2025-09-20T22:37:32.753642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "with open(\"res/foundation/foundation.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_foundation = json.load(f)\n",
    "\n",
    "with open(\"res/sara/sara_combos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_sara = json.load(f)\n",
    "\n",
    "foundation = data_foundation[\"foundation\"]\n",
    "vowel = data_sara\n",
    "dependent = []\n",
    "exception = [\"อ\"]\n",
    "\n",
    "print(len(foundation))\n",
    "print(len(vowel))"
   ],
   "id": "cf10115c48904caa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "79\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T22:37:32.779032Z",
     "start_time": "2025-09-20T22:37:32.768671Z"
    }
   },
   "cell_type": "code",
   "source": "import json\nfrom typing import List, Dict, Optional, Tuple\n\n# Load the data\nwith open(\"res/foundation/foundation.json\", \"r\", encoding=\"utf-8\") as f:\n    data_foundation = json.load(f)\n\nwith open(\"res/sara/sara_combos.json\", \"r\", encoding=\"utf-8\") as f:\n    sara_combos = json.load(f)\n\n# Initialize character classifications\nfoundation = data_foundation[\"foundation\"]\nvowel_patterns = sara_combos\nexception_chars = [\"อ\", \"ว\"]  # Both can act as foundation or vowel component\n\n# Leading vowels that appear before consonants but read after\nleading_vowels = [\"เ\", \"แ\", \"โ\", \"ใ\", \"ไ\"]\n\n# Dependent marks (tone marks and other diacritics)  \ndependent_marks = [\"่\", \"้\", \"๊\", \"๋\", \"์\", \"็\", \"ํ\"]\nvowel_marks = [\"ั\", \"ิ\", \"ี\", \"ึ\", \"ื\", \"ุ\", \"ู\"]\n\ndef classifyThaiGraphemes(thai: str) -> List[Dict]:\n    \"\"\"\n    Classify Thai graphemes with their class and reading order.\n    \n    Returns a list of dictionaries containing:\n    - grapheme: The pattern template (e.g. \"xา\" for vowel patterns)\n    - instance: The actual matched text (e.g. \"ยา\")\n    - class: \"foundation\", \"vowel\", \"dependent\", or \"exception\"  \n    - read_order: Integer indicating reading sequence\n    - pattern: For vowels, the pattern that was matched\n    - role: \"initial\" (x), \"vowel\", or \"final\" (f)\n    - start_pos: Starting position in the original string\n    - positions: All positions occupied by this unit\n    \"\"\"\n    if not thai:\n        return []\n    \n    result = []\n    used_positions = set()  # Track which positions have been consumed\n    \n    # Try to match vowel patterns at each position\n    for start_pos in range(len(thai)):\n        if start_pos in used_positions:\n            continue\n            \n        # Try to match a vowel pattern starting here\n        match_result = find_best_vowel_match(thai, start_pos, used_positions)\n        \n        if match_result:\n            matched_pattern, pattern_template, positions_used, x_positions, f_positions = match_result\n            \n            # Calculate vowel-only positions (excluding x and f)\n            vowel_only_positions = [p for p in positions_used if p not in x_positions and p not in f_positions]\n            \n            # Add the vowel unit - grapheme is the pattern, instance is the actual text\n            vowel_unit = {\n                'grapheme': pattern_template,  # The pattern (e.g. \"xา\")\n                'instance': matched_pattern,   # The actual matched text (e.g. \"ยา\")\n                'class': 'vowel',\n                'pattern': pattern_template,\n                'start_pos': min(vowel_only_positions) if vowel_only_positions else min(positions_used),\n                'positions': positions_used,\n                'role': 'vowel',\n                'read_order': 1  # Vowel is always read second\n            }\n            result.append(vowel_unit)\n            \n            # Add initial consonant(s) (x)\n            if x_positions:\n                x_grapheme = ''.join(thai[p] for p in x_positions)\n                result.append({\n                    'grapheme': x_grapheme,\n                    'instance': x_grapheme,  # For non-vowels, grapheme and instance are the same\n                    'class': 'foundation' if len(x_positions) == 1 else 'cluster',\n                    'start_pos': min(x_positions),\n                    'positions': x_positions,\n                    'role': 'initial',\n                    'read_order': 0  # Initial is always read first\n                })\n            \n            # Add final consonant (f)\n            if f_positions:\n                f_grapheme = ''.join(thai[p] for p in f_positions)\n                result.append({\n                    'grapheme': f_grapheme,\n                    'instance': f_grapheme,  # For non-vowels, grapheme and instance are the same\n                    'class': 'foundation',\n                    'start_pos': min(f_positions),\n                    'positions': f_positions,\n                    'role': 'final',\n                    'read_order': 2  # Final is always read third\n                })\n            \n            # Mark all positions as used\n            used_positions.update(positions_used)\n    \n    # Add any remaining unmatched characters\n    for i in range(len(thai)):\n        if i not in used_positions:\n            char = thai[i]\n            result.append({\n                'grapheme': char,\n                'instance': char,\n                'class': classify_single_char(char),\n                'start_pos': i,\n                'positions': [i],\n                'role': 'standalone',\n                'read_order': 3 + i  # Standalone chars come after matched patterns\n            })\n            used_positions.add(i)\n    \n    return sorted(result, key=lambda x: (x['read_order'], x['start_pos']))\n\ndef find_best_vowel_match(text: str, start_pos: int, used_positions: set) -> Optional[Tuple]:\n    \"\"\"\n    Find the best matching vowel pattern at the given position.\n    Returns: (matched_string, pattern_template, positions_used, x_positions, f_positions)\n    \"\"\"\n    best_match = None\n    best_length = 0\n    \n    # Try each vowel pattern\n    for pattern in vowel_patterns:\n        match_result = try_match_vowel_pattern(text, start_pos, pattern, used_positions)\n        \n        if match_result:\n            matched, positions_used, x_positions, f_positions = match_result\n            if len(positions_used) > best_length:\n                best_match = (matched, pattern, positions_used, x_positions, f_positions)\n                best_length = len(positions_used)\n    \n    return best_match\n\ndef try_match_vowel_pattern(text: str, start_pos: int, pattern: str, used_positions: set) -> Optional[Tuple]:\n    \"\"\"\n    Try to match a specific vowel pattern.\n    x = initial consonant(s) - can be multiple consecutive foundations (cluster)\n    f = final consonant - single foundation that comes after the vowel\n    Other characters must match exactly.\n    \n    Returns: (matched_string, positions_used, x_positions, f_positions)\n    \"\"\"\n    matched_chars = []\n    positions_used = []\n    x_positions = []\n    f_positions = []\n    text_pos = start_pos\n    pattern_pos = 0\n    \n    # For patterns starting with x, we need to be at a foundation position\n    if pattern[0] == 'x' and start_pos < len(text):\n        if text[start_pos] not in foundation and text[start_pos] not in exception_chars:\n            return None\n    \n    while pattern_pos < len(pattern) and text_pos < len(text):\n        pattern_char = pattern[pattern_pos]\n        \n        if pattern_char == 'x':\n            # x can be multiple consecutive foundations (cluster)\n            if text[text_pos] in foundation or text[text_pos] in exception_chars:\n                matched_chars.append(text[text_pos])\n                x_positions.append(text_pos)\n                positions_used.append(text_pos)\n                text_pos += 1\n                \n                # Check for cluster - look ahead to see if we should consume more foundations\n                # This is a simplified version - you may need more sophisticated cluster detection\n                while (text_pos < len(text) and \n                       (text[text_pos] in foundation or text[text_pos] in exception_chars) and\n                       # Make sure we're not consuming what should be 'f'\n                       (pattern_pos + 1 >= len(pattern) or pattern[pattern_pos + 1] != 'f') and\n                       # Make sure next pattern char isn't a specific vowel mark\n                       (pattern_pos + 1 >= len(pattern) or pattern[pattern_pos + 1] in ['x', 'f'])):\n                    matched_chars.append(text[text_pos])\n                    x_positions.append(text_pos)\n                    positions_used.append(text_pos)\n                    text_pos += 1\n                    # Only advance pattern if the pattern has another 'x'\n                    if pattern_pos + 1 < len(pattern) and pattern[pattern_pos + 1] == 'x':\n                        pattern_pos += 1\n                    else:\n                        break\n            else:\n                return None\n                \n        elif pattern_char == 'f':\n            # f is a single final consonant\n            if text[text_pos] in foundation or text[text_pos] in exception_chars:\n                matched_chars.append(text[text_pos])\n                f_positions.append(text_pos)\n                positions_used.append(text_pos)\n                text_pos += 1\n            else:\n                return None\n                \n        else:\n            # Must match exactly (vowel marks, tone marks, etc.)\n            if text[text_pos] == pattern_char:\n                matched_chars.append(text[text_pos])\n                positions_used.append(text_pos)\n                text_pos += 1\n            else:\n                return None\n        \n        pattern_pos += 1\n    \n    # Check if we matched the full pattern\n    if pattern_pos != len(pattern):\n        return None\n    \n    # Check if any non-foundation positions are already used\n    for pos in positions_used:\n        if pos in used_positions and pos not in x_positions and pos not in f_positions:\n            return None\n    \n    # Validate: if pattern has 'f', we must have found a final consonant\n    if 'f' in pattern and not f_positions:\n        return None\n    \n    return (''.join(matched_chars), positions_used, x_positions, f_positions)\n\ndef classify_single_char(char: str) -> str:\n    \"\"\"Classify a single Thai character.\"\"\"\n    if char in foundation:\n        return 'foundation'\n    elif char in exception_chars:\n        return 'exception'\n    elif char in dependent_marks:\n        return 'dependent'\n    elif char in vowel_marks or char in leading_vowels or char in [\"า\", \"ะ\", \"ำ\", \"ฤ\", \"ฦ\", \"ๅ\"]:\n        return 'vowel'\n    else:\n        return 'unknown'\n\n# Test cases\nthai1 = \"ยา\"  # simple: x=ย, vowel=า\nthai2 = \"เด็ก\"  # pattern เx็f: x=ด, vowel=เ็, f=ก\nthai3 = \"คน\"  # x=ค, f=น (hidden vowel)\nthai4 = \"เลว\"  # pattern เxf: x=ล, vowel=เ, f=ว\n\nthaihard1 = \"เกรียน\"  # pattern เxียf: x=กร (cluster), vowel=เีย, f=น\nthaihard2 = \"เอา\"  # pattern เxา: x=อ (silent), vowel=เา\nthaihard3 = \"อย่า\"  # x=อ (silent), vowel=่า\nthaihard4 = \"เอือม\"  # pattern เxือf: x=อ, vowel=เือ, f=ม\nthaihard5 = \"ไกล\"  # pattern ไxf: x=ก, vowel=ไ, f=ล\n\n# Test the function\nprint(\"Testing Thai grapheme classification:\\n\")\nprint(\"Format: [read_order] 'grapheme' (class) role [instance]\\n\")\nprint(\"-\" * 50)\n\ntest_cases = [\n    (thai1, \"simple: foundation + vowel\"),\n    (thai2, \"เx็f pattern\"),\n    (thai3, \"foundation + final\"),\n    (thai4, \"เxf pattern\")\n]\n\nfor thai_text, description in test_cases:\n    print(f\"\\n'{thai_text}' - {description}:\")\n    result = classifyThaiGraphemes(thai_text)\n    for item in result:\n        instance_str = f\" [{item['instance']}]\" if item['grapheme'] != item['instance'] else \"\"\n        pos_str = f\" pos={item['positions']}\" if len(item['positions']) > 1 else f\" pos={item['start_pos']}\"\n        print(f\"  [{item['read_order']}] '{item['grapheme']}' ({item['class']}) {item['role']}{instance_str}{pos_str}\")",
   "id": "ef04abc8e4592df9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Thai grapheme classification:\n",
      "\n",
      "Format: [read_order] 'grapheme' (class) role [instance]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "'ยา' - simple: foundation + vowel:\n",
      "  [0] 'ย' (foundation) initial pos=0\n",
      "  [1] 'xา' (vowel) vowel [ยา] pos=[0, 1]\n",
      "\n",
      "'เด็ก' - เx็f pattern:\n",
      "  [0] 'ด' (foundation) initial pos=1\n",
      "  [1] 'เx็f' (vowel) vowel [เด็ก] pos=[0, 1, 2, 3]\n",
      "  [2] 'ก' (foundation) final pos=3\n",
      "\n",
      "'คน' - foundation + final:\n",
      "  [3] 'ค' (foundation) standalone pos=0\n",
      "  [4] 'น' (foundation) standalone pos=1\n",
      "\n",
      "'เลว' - เxf pattern:\n",
      "  [0] 'ลว' (cluster) initial pos=[1, 2]\n",
      "  [1] 'เx' (vowel) vowel [เลว] pos=[0, 1, 2]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "thp416ejr6",
   "source": "# Test with all provided examples\nprint(\"=\"*60)\nprint(\"Testing all examples including hard cases:\")\nprint(\"=\"*60)\n\nall_test_cases = [\n    (thai1, \"simple: foundation + vowel\"),\n    (thai2, \"vowel appears first\"), \n    (thai3, \"foundation + final\"),\n    (thai4, \"leading vowel + foundation + ว\"),\n    (thaihard1, \"cluster with multi-part vowel\"),\n    (thaihard2, \"อ as silent foundation\"),\n    (thaihard3, \"อ stress test with atomic vowel\"),\n    (thaihard4, \"complex อ: foundation then vowel part\"),\n    (thaihard5, \"ไ read after กล cluster\")\n]\n\nfor thai_text, description in all_test_cases:\n    print(f\"\\n'{thai_text}' - {description}:\")\n    result = classifyThaiGraphemes(thai_text)\n    \n    # Show results sorted by reading order\n    print(\"  By reading order:\")\n    for item in sorted(result, key=lambda x: x['read_order']):\n        instance_str = f\" [{item['instance']}]\" if item['grapheme'] != item['instance'] else \"\"\n        print(f\"    [{item['read_order']}] '{item['grapheme']}' ({item['class']}) role={item['role']}{instance_str}\")\n    \n    # Show results in original position order\n    print(\"  By position:\")\n    for item in sorted(result, key=lambda x: x['start_pos']):\n        instance_str = f\" [{item['instance']}]\" if item['grapheme'] != item['instance'] else \"\"\n        positions_str = f\" (spans positions {item['positions']})\" if len(item['positions']) > 1 else \"\"\n        print(f\"    pos {item['start_pos']}: '{item['grapheme']}' ({item['class']}) role={item['role']} -> read at {item['read_order']}{positions_str}{instance_str}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T22:37:32.790068Z",
     "start_time": "2025-09-20T22:37:32.782065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Testing all examples including hard cases:\n",
      "============================================================\n",
      "\n",
      "'ยา' - simple: foundation + vowel:\n",
      "  By reading order:\n",
      "    [0] 'ย' (foundation) role=initial\n",
      "    [1] 'xา' (vowel) role=vowel [ยา]\n",
      "  By position:\n",
      "    pos 0: 'ย' (foundation) role=initial -> read at 0\n",
      "    pos 1: 'xา' (vowel) role=vowel -> read at 1 (spans positions [0, 1]) [ยา]\n",
      "\n",
      "'เด็ก' - vowel appears first:\n",
      "  By reading order:\n",
      "    [0] 'ด' (foundation) role=initial\n",
      "    [1] 'เx็f' (vowel) role=vowel [เด็ก]\n",
      "    [2] 'ก' (foundation) role=final\n",
      "  By position:\n",
      "    pos 0: 'เx็f' (vowel) role=vowel -> read at 1 (spans positions [0, 1, 2, 3]) [เด็ก]\n",
      "    pos 1: 'ด' (foundation) role=initial -> read at 0\n",
      "    pos 3: 'ก' (foundation) role=final -> read at 2\n",
      "\n",
      "'คน' - foundation + final:\n",
      "  By reading order:\n",
      "    [3] 'ค' (foundation) role=standalone\n",
      "    [4] 'น' (foundation) role=standalone\n",
      "  By position:\n",
      "    pos 0: 'ค' (foundation) role=standalone -> read at 3\n",
      "    pos 1: 'น' (foundation) role=standalone -> read at 4\n",
      "\n",
      "'เลว' - leading vowel + foundation + ว:\n",
      "  By reading order:\n",
      "    [0] 'ลว' (cluster) role=initial\n",
      "    [1] 'เx' (vowel) role=vowel [เลว]\n",
      "  By position:\n",
      "    pos 0: 'เx' (vowel) role=vowel -> read at 1 (spans positions [0, 1, 2]) [เลว]\n",
      "    pos 1: 'ลว' (cluster) role=initial -> read at 0 (spans positions [1, 2])\n",
      "\n",
      "'เกรียน' - cluster with multi-part vowel:\n",
      "  By reading order:\n",
      "    [0] 'กร' (cluster) role=initial\n",
      "    [1] 'เx' (vowel) role=vowel [เกร]\n",
      "    [6] 'ี' (vowel) role=standalone\n",
      "    [7] 'ย' (foundation) role=standalone\n",
      "    [8] 'น' (foundation) role=standalone\n",
      "  By position:\n",
      "    pos 0: 'เx' (vowel) role=vowel -> read at 1 (spans positions [0, 1, 2]) [เกร]\n",
      "    pos 1: 'กร' (cluster) role=initial -> read at 0 (spans positions [1, 2])\n",
      "    pos 3: 'ี' (vowel) role=standalone -> read at 6\n",
      "    pos 4: 'ย' (foundation) role=standalone -> read at 7\n",
      "    pos 5: 'น' (foundation) role=standalone -> read at 8\n",
      "\n",
      "'เอา' - อ as silent foundation:\n",
      "  By reading order:\n",
      "    [0] 'อ' (foundation) role=initial\n",
      "    [1] 'เxา' (vowel) role=vowel [เอา]\n",
      "  By position:\n",
      "    pos 0: 'เxา' (vowel) role=vowel -> read at 1 (spans positions [0, 1, 2]) [เอา]\n",
      "    pos 1: 'อ' (foundation) role=initial -> read at 0\n",
      "\n",
      "'อย่า' - อ stress test with atomic vowel:\n",
      "  By reading order:\n",
      "    [3] 'อ' (exception) role=standalone\n",
      "    [4] 'ย' (foundation) role=standalone\n",
      "    [5] '่' (dependent) role=standalone\n",
      "    [6] 'า' (vowel) role=standalone\n",
      "  By position:\n",
      "    pos 0: 'อ' (exception) role=standalone -> read at 3\n",
      "    pos 1: 'ย' (foundation) role=standalone -> read at 4\n",
      "    pos 2: '่' (dependent) role=standalone -> read at 5\n",
      "    pos 3: 'า' (vowel) role=standalone -> read at 6\n",
      "\n",
      "'เอือม' - complex อ: foundation then vowel part:\n",
      "  By reading order:\n",
      "    [0] 'อ' (foundation) role=initial\n",
      "    [1] 'เxือf' (vowel) role=vowel [เอือม]\n",
      "    [2] 'ม' (foundation) role=final\n",
      "  By position:\n",
      "    pos 0: 'เxือf' (vowel) role=vowel -> read at 1 (spans positions [0, 1, 2, 3, 4]) [เอือม]\n",
      "    pos 1: 'อ' (foundation) role=initial -> read at 0\n",
      "    pos 4: 'ม' (foundation) role=final -> read at 2\n",
      "\n",
      "'ไกล' - ไ read after กล cluster:\n",
      "  By reading order:\n",
      "    [0] 'กล' (cluster) role=initial\n",
      "    [1] 'ไx' (vowel) role=vowel [ไกล]\n",
      "  By position:\n",
      "    pos 0: 'ไx' (vowel) role=vowel -> read at 1 (spans positions [0, 1, 2]) [ไกล]\n",
      "    pos 1: 'กล' (cluster) role=initial -> read at 0 (spans positions [1, 2])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T22:37:32.796550Z",
     "start_time": "2025-09-20T22:37:32.795324Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c6accf4c8f55dc58",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
